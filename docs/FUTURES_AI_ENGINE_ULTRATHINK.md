# üß† Futures AI Engine - Ultrathink Analysis & Improvement Plan

**–î–∞—Ç–∞:** 2025-12-15
**–ê–≤—Ç–æ—Ä:** Architecture Review
**–¶–µ–ª—å:** –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ futures_analysis_service.py –∏ –ø–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏–π –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏, —Å–Ω–∏–∂–µ–Ω–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏

---

## üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

### ‚úÖ –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –û–¢–õ–ò–ß–ù–û

1. **Pipeline –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π:** `data ‚Üí context ‚Üí levels ‚Üí scenarios ‚Üí quality`
2. **MTF –∫–æ–Ω—Ç–µ–∫—Å—Ç:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ 1h/4h/1d –¥–ª—è macro-view
3. **Structured output + JSON schema:** –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON –æ—Ç LLM
4. **–ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ —Ç–∞–π–º—Ñ—Ä–µ–π–º:** ATR-based stops/targets
5. **Data quality score:** Underrated, –Ω–æ –æ—á–µ–Ω—å –≤–∞–∂–Ω–æ

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏–ª—å–Ω–∞—è**, –Ω–æ –µ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ –¥–µ—Ç–∞–ª—è—Ö.

---

## üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã

### ‚ùå –ü–†–û–ë–õ–ï–ú–ê #1: –¢–µ–∫—Å—Ç–æ–≤–∞—è –∫–∞—à–∞ –¥–ª—è LLM

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:**
```python
# –°—Ç—Ä–æ–∫–∏ 599-790: –û–≥—Ä–æ–º–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç (~200 —Å—Ç—Ä–æ–∫)
prompt = f"""–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–µ–π–¥–µ—Ä —Ñ—å—é—á–µ—Ä—Å–æ–≤...

üìä **–¢–ï–ö–£–©–ê–Ø –¶–ï–ù–ê**: ${current_price:.2f}

üìà **–†–´–ù–û–ß–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢**:
- –¢—Ä–µ–Ω–¥: {market_context.get('trend', 'unknown')}
- Bias: {market_context.get('bias', 'neutral')}
...
"""
```

**–ü—Ä–æ–±–ª–µ–º–∞:**
- LLM –ø–æ–ª—É—á–∞–µ—Ç "–∫–∞—à—É" –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ —Ü–∏—Ñ—Ä
- –ù–∞—á–∏–Ω–∞–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏
- –í—ã–±–∏—Ä–∞–µ—Ç "—Å–∞–º–æ–µ –∑–≤—É—á–Ω–æ–µ" (Fear&Greed) –∏ –∏–≥–Ω–æ—Ä–∏—Ç –º–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä—É
- –î–æ—Ä–æ–≥–æ: ~2000+ tokens –Ω–∞ –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å

**Impact:** üî¥ HIGH - —Å–Ω–∏–∂–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –∏ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å

---

### ‚ùå –ü–†–û–ë–õ–ï–ú–ê #2: –ù–µ—Ç —Å–∂–∞—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ü–µ–Ω—ã

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:**
```python
# LLM –ø–æ–ª—É—á–∞–µ—Ç:
# - 200 —Å–≤–µ—á–µ–π –≤ –≤–∏–¥–µ indicators
# - Support/resistance —Å–ø–∏—Å–∫–∏
# - –ù–û –ù–ï –ü–û–õ–£–ß–ê–ï–¢ –°–¢–†–£–ö–¢–£–†–£!
```

**–ß—Ç–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç:**
- Swing highs/lows –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N —Å–≤–µ—á–µ–π
- Range high/low (20/50 —Å–≤–µ—á–µ–π)
- Distance to support/resistance
- Trend state by timeframe (1h/4h/1d bull/bear/side + strength)
- Volatility regime (compression/expansion)
- Volume profile lite (POC/VAH/VAL –∏–ª–∏ HVN/LVN proxy)

**Impact:** üî¥ HIGH - LLM "—É–≥–∞–¥—ã–≤–∞–µ—Ç" —É—Ä–æ–≤–Ω–∏ –≤–º–µ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã

---

### ‚ùå –ü–†–û–ë–õ–ï–ú–ê #3: Liquidation data –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:**
```python
# –°—Ç—Ä–æ–∫–∏ 130-150: –°–æ–±–∏—Ä–∞–µ–º liquidation_data
liquidation_data = await self.binance.get_liquidation_history(...)

# –°—Ç—Ä–æ–∫–∏ 191-204: –ü–µ—Ä–µ–¥–∞–µ–º –≤ _generate_scenarios
scenarios = await self._generate_scenarios(
    ...
    liquidation_data=liquidation_data,  # ‚úÖ –ü–µ—Ä–µ–¥–∞–µ–º
    ...
)

# –°—Ç—Ä–æ–∫–∏ 563-575: _ai_generate_scenarios
async def _ai_generate_scenarios(
    self,
    ...
    # ‚ùå –ù–ï–¢ liquidation_data –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö!!!
)
```

**Impact:** üü° MEDIUM - —Ç–µ—Ä—è–µ–º —Ç–æ–ø–æ–≤—ã–π edge (liquidity sweeps, clusters)

---

### ‚ùå –ü–†–û–ë–õ–ï–ú–ê #4: Fear&Greed —Å–ª–∏—à–∫–æ–º —Å–∏–ª—å–Ω—ã–π –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö TF

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:**
```python
# –°—Ç—Ä–æ–∫–∏ 382-392: Fear & Greed bias (contrarian) - –°–ê–ú–´–ô –í–ê–ñ–ù–´–ô!
if fg_value < 20:  # Extreme Fear = BUY OPPORTUNITY!
    bias_score += 3  # üö® –°–∞–º—ã–π —Å–∏–ª—å–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä!
elif fg_value < 30:  # Fear
    bias_score += 2
elif fg_value > 80:  # Extreme Greed = SELL SIGNAL!
    bias_score -= 3
elif fg_value > 70:  # Greed
    bias_score -= 2
```

**–ü—Ä–æ–±–ª–µ–º–∞:**
- Fear&Greed –¥–ª—è 1h/4h —á–∞—Å—Ç–æ **—à—É–º**
- –î–ª—è 1d/1w —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ
- –ù–∞ —Å–∏–ª—å–Ω–æ–º —Ç—Ä–µ–Ω–¥–µ contrarian –º–æ–∂–µ—Ç –¥–∞—Ç—å "–ª–æ–≤–∏ –Ω–æ–∂–∏"

**Impact:** üü° MEDIUM - –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å –ø–ª–æ—Ö–∏–µ —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ 1h/4h

---

### ‚ùå –ü–†–û–ë–õ–ï–ú–ê #5: –°—Ç—Ä–∞–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ max_scenarios

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:**
```python
# –°—Ç—Ä–æ–∫–∞ 639: –ü—Ä–æ—Å–∏–º LLM —Å–æ–∑–¥–∞—Ç—å max_scenarios + 2
**–ó–ê–î–ê–ß–ê**: –°–æ–∑–¥–∞–π {max_scenarios + 2} –†–ê–ó–ù–û–û–ë–†–ê–ó–ù–´–• —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤

# –°—Ç—Ä–æ–∫–∞ 947: –†–µ–∂–µ–º –¥–æ max(max_scenarios, 3)
return adapted_scenarios[:max(max_scenarios, 3)]
```

**–ü—Ä–æ–±–ª–µ–º–∞:**
- –ï—Å–ª–∏ `max_scenarios=3`, –ø—Ä–æ—Å–∏–º 5, –Ω–æ –æ—Ç–¥–∞–µ–º 3
- –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ confidence –º–æ–∂–µ—Ç –¥–∞—Ç—å 3 long'–∞ (–Ω–µ—Ç diversity)

**Impact:** üü¢ LOW - –Ω–æ –ª–æ–≥–∏–∫–∞ —Å—Ç—Ä–∞–Ω–Ω–∞—è –∏ –º–æ–∂–µ—Ç –¥–∞—Ç—å –æ–¥–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏

---

### ‚ùå –ü–†–û–ë–õ–ï–ú–ê #6: –ö–æ–Ω—Ñ–ª–∏–∫—Ç "–º–∏–Ω–∏–º—É–º 1 short –∏ 1 long"

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:**
```python
# –°—Ç—Ä–æ–∫–∏ 672-676:
**–í–ê–ñ–ù–û - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø**:
1. –ú–ò–ù–ò–ú–£–ú 1 LONG —Å—Ü–µ–Ω–∞—Ä–∏–π –∏ –ú–ò–ù–ò–ú–£–ú 1 SHORT —Å—Ü–µ–Ω–∞—Ä–∏–π
   (–¥–∞–∂–µ –µ—Å–ª–∏ —Ä—ã–Ω–æ–∫ —Å–∏–ª—å–Ω–æ bearish/bullish!)
```

**–ü—Ä–æ–±–ª–µ–º–∞:**
- –ò–Ω–æ–≥–¥–∞ —Ä—ã–Ω–æ–∫ —Ä–µ–∞–ª—å–Ω–æ "one-sided"
- Forced short/long –±—É–¥–µ—Ç –º—É—Å–æ—Ä–æ–º —Å –Ω–∏–∑–∫–æ–π confidence
- –ù–æ diversity –≤–∞–∂–Ω–æ

**–†–µ—à–µ–Ω–∏–µ:**
- –ü—É—Å—Ç—å LLM –¥–∞—ë—Ç short/long, –Ω–æ –ø–æ–º–µ—á–∞–µ—Ç `scenario_class: primary/alternative/hedge`
- –ë–æ—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ primary + alt
- Hedge ‚Äî –æ—Ç–¥–µ–ª—å–Ω–æ–π –∫–Ω–æ–ø–∫–æ–π

**Impact:** üü¢ LOW - –Ω–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å UX

---

### ‚ùå –ü–†–û–ë–õ–ï–ú–ê #7: –î–æ—Ä–æ–≥–æ –∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:**
- –û–≥—Ä–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (~2000 tokens)
- LLM "–ø—Ä–∏–¥—É–º—ã–≤–∞–µ—Ç" —Ü–µ–Ω—ã (–≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏)
- –î–æ—Ä–æ–≥–æ –Ω–∞ gpt-4o

**–†–µ—à–µ–Ω–∏–µ:**
- 2-—Å—Ç–∞–¥–∏–π–Ω–∞—è —Å—Ö–µ–º–∞:
  1. **Rule/Math —Å–ª–æ–π:** –°—á–∏—Ç–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É (—É—Ä–æ–≤–Ω–∏, ATR, HH/HL)
  2. **LLM —Å–ª–æ–π:** –¢–æ–ª—å–∫–æ "—É–ø–∞–∫–æ–≤–∫–∞ –≤ —Å—Ü–µ–Ω–∞—Ä–∏–∏" + reasoning

**Impact:** üî¥ HIGH - —Å–Ω–∏–∂–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å –∏ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏

---

## üéØ –ü–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏–π

### üî• –ì–ª–∞–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ #1: JSON –≤–º–µ—Å—Ç–æ —Ç–µ–∫—Å—Ç–∞

**–ö–∞–∫ —Å–µ–π—á–∞—Å:**
```python
prompt = f"""
üìà **–†–´–ù–û–ß–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢**:
- –¢—Ä–µ–Ω–¥: {market_context.get('trend')}
- Bias: {market_context.get('bias')}
"""
```

**–ö–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å:**
```python
market_data = {
    "current_price": current_price,
    "context": market_context,
    "levels": {
        "support_candidates": supports,
        "resistance_candidates": resistances,
        "ema_levels": ema_levels,
        "vwap": vwap
    },
    "indicators": {
        "rsi": indicators.get("rsi"),
        "adx": indicators.get("adx"),
        "atr": indicators.get("atr"),
        "atr_percent": indicators.get("atr_percent")
    },
    "structure": {
        "swing_highs": [...],  # NEW!
        "swing_lows": [...],   # NEW!
        "range_high": 96500,   # NEW!
        "range_low": 94200,    # NEW!
        "trend_state_1h": "bullish_strong",  # NEW!
        "trend_state_4h": "bullish_weak",    # NEW!
        "volatility_regime": "expansion"     # NEW!
    },
    "liquidation": {  # NEW!
        "clusters_above": [{price: 96000, intensity: "high"}],
        "clusters_below": [{price: 93500, intensity: "medium"}],
        "last_24h_spike": False,
        "net_bias": "long"
    }
}

prompt = f"""You are a professional trader. Analyze the market data and generate scenarios.

MARKET DATA (JSON):
{json.dumps(market_data, indent=2)}

RULES:
- Use support_candidates and resistance_candidates for entry/stop/targets
- Do NOT invent prices - select from candidates
- Adapt stops/targets to timeframe {timeframe}
- Return structured JSON
"""
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ LLM –ø–æ–ª—É—á–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- ‚úÖ –ö–æ—Ä–æ—á–µ –ø—Ä–æ–º–ø—Ç = –¥–µ—à–µ–≤–ª–µ
- ‚úÖ –ú–µ–Ω—å—à–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π

---

### üî• –ì–ª–∞–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ #2: Price Structure Summary

**–î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ `_calculate_price_structure()`:**

```python
def _calculate_price_structure(
    self,
    klines: pd.DataFrame,
    current_price: float,
    indicators: Dict,
    timeframe: str
) -> Dict[str, Any]:
    """
    –†–∞—Å—Å—á–∏—Ç–∞—Ç—å —Å–∂–∞—Ç—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ü–µ–Ω—ã –¥–ª—è LLM

    Returns:
        {
            "swing_highs": [{price: 96500, tf: "1h", distance_pct: 1.2}],
            "swing_lows": [{price: 93800, tf: "1h", distance_pct: -1.5}],
            "range_high": 96500,
            "range_low": 93800,
            "range_size_pct": 2.8,
            "current_position_in_range": 0.65,  # 65% –æ—Ç low –∫ high
            "trend_state": {
                "1h": "bullish_strong",
                "4h": "bullish_weak",
                "1d": "sideways"
            },
            "volatility_regime": "expansion",  # or "compression"
            "distance_to_support": -1.2,  # %
            "distance_to_resistance": 0.8  # %
        }
    """
    structure = {}

    # 1. Swing points (–∏—Å–ø–æ–ª—å–∑—É—è peaks detection)
    from scipy.signal import find_peaks

    highs = klines['high'].values
    lows = klines['low'].values

    # –ù–∞—Ö–æ–¥–∏–º swing highs
    swing_high_indices, _ = find_peaks(highs, distance=5)
    swing_highs = []
    for idx in swing_high_indices[-5:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5
        price = highs[idx]
        distance_pct = ((price - current_price) / current_price) * 100
        swing_highs.append({
            "price": round(price, 2),
            "distance_pct": round(distance_pct, 2)
        })

    # –ù–∞—Ö–æ–¥–∏–º swing lows
    swing_low_indices, _ = find_peaks(-lows, distance=5)
    swing_lows = []
    for idx in swing_low_indices[-5:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5
        price = lows[idx]
        distance_pct = ((price - current_price) / current_price) * 100
        swing_lows.append({
            "price": round(price, 2),
            "distance_pct": round(distance_pct, 2)
        })

    structure["swing_highs"] = swing_highs
    structure["swing_lows"] = swing_lows

    # 2. Range high/low (–ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–≤–µ—á–µ–π)
    lookback = 50 if timeframe in ["1h", "4h"] else 30
    recent_highs = klines['high'].tail(lookback)
    recent_lows = klines['low'].tail(lookback)

    range_high = recent_highs.max()
    range_low = recent_lows.min()
    range_size_pct = ((range_high - range_low) / range_low) * 100

    structure["range_high"] = round(range_high, 2)
    structure["range_low"] = round(range_low, 2)
    structure["range_size_pct"] = round(range_size_pct, 2)

    # Position in range
    if range_high > range_low:
        position_in_range = (current_price - range_low) / (range_high - range_low)
        structure["current_position_in_range"] = round(position_in_range, 2)

    # 3. Trend state by timeframe (–∏—Å–ø–æ–ª—å–∑—É—è EMA cross + ADX)
    # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å MTF –¥–∞–Ω–Ω—ã–µ
    ema_20 = indicators.get("ema_20")
    ema_50 = indicators.get("ema_50")
    adx = indicators.get("adx", 20)

    if ema_20 and ema_50:
        if current_price > ema_20 > ema_50:
            trend = "bullish"
            strength = "strong" if adx > 30 else "weak"
        elif current_price < ema_20 < ema_50:
            trend = "bearish"
            strength = "strong" if adx > 30 else "weak"
        else:
            trend = "sideways"
            strength = "weak"

        structure["trend_state"] = {
            timeframe: f"{trend}_{strength}"
        }

    # 4. Volatility regime
    atr = indicators.get("atr")
    atr_pct = indicators.get("atr_percent", 2.0)

    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π ATR —Å –µ–≥–æ MA
    # –£–ø—Ä–æ—â–µ–Ω–Ω–æ: –µ—Å–ª–∏ ATR > 2.5% = expansion, < 1.5% = compression
    if atr_pct > 2.5:
        structure["volatility_regime"] = "expansion"
    elif atr_pct < 1.5:
        structure["volatility_regime"] = "compression"
    else:
        structure["volatility_regime"] = "normal"

    return structure
```

---

### üî• –ì–ª–∞–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ #3: Liquidation Clusters

**–î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ `_aggregate_liquidation_clusters()`:**

```python
def _aggregate_liquidation_clusters(
    self,
    liquidation_data: Optional[Dict],
    current_price: float
) -> Dict[str, Any]:
    """
    –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å liquidation data –≤ clusters –¥–ª—è LLM

    Returns:
        {
            "clusters_above": [
                {price: 96000, intensity: "high", volume_usd: 5000000},
                {price: 97500, intensity: "medium", volume_usd: 2000000}
            ],
            "clusters_below": [...],
            "last_24h_liq_spike": True,
            "spike_magnitude": "large",
            "net_liq_bias": "long"  # long/short/neutral
        }
    """
    if not liquidation_data or not liquidation_data.get("liquidations"):
        return {
            "clusters_above": [],
            "clusters_below": [],
            "last_24h_liq_spike": False,
            "net_liq_bias": "neutral"
        }

    liquidations = liquidation_data.get("liquidations", [])

    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ longs/shorts
    long_liqs = [l for l in liquidations if l.get("side") == "BUY"]  # Long liquidations
    short_liqs = [l for l in liquidations if l.get("side") == "SELL"]  # Short liquidations

    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ —Ü–µ–Ω–æ–≤—ã–º –∑–æ–Ω–∞–º (bins –ø–æ 1% –æ—Ç current_price)
    bin_size = current_price * 0.01  # 1% bins

    def aggregate_to_bins(liqs, current_price):
        from collections import defaultdict
        bins = defaultdict(lambda: {"volume": 0, "count": 0})

        for liq in liqs:
            price = liq.get("price", 0)
            volume = liq.get("quantity", 0) * price  # USD value

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º bin
            bin_key = round(price / bin_size) * bin_size
            bins[bin_key]["volume"] += volume
            bins[bin_key]["count"] += 1

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ volume
        sorted_bins = sorted(
            bins.items(),
            key=lambda x: x[1]["volume"],
            reverse=True
        )

        # –¢–æ–ø 5 clusters
        clusters = []
        for price, data in sorted_bins[:5]:
            intensity = "high" if data["volume"] > 1000000 else "medium" if data["volume"] > 500000 else "low"
            clusters.append({
                "price": round(price, 2),
                "intensity": intensity,
                "volume_usd": round(data["volume"], 0)
            })

        return clusters

    # Clusters –≤—ã—à–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã (short liquidations = targets for longs)
    clusters_above = [c for c in aggregate_to_bins(short_liqs, current_price) if c["price"] > current_price]

    # Clusters –Ω–∏–∂–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã (long liquidations = targets for shorts)
    clusters_below = [c for c in aggregate_to_bins(long_liqs, current_price) if c["price"] < current_price]

    # Spike detection (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 1h vs —Å—Ä–µ–¥–Ω–∏–π –∑–∞ 24h)
    import time
    now = time.time() * 1000
    one_hour_ago = now - (60 * 60 * 1000)

    recent_liqs = [l for l in liquidations if l.get("time", 0) > one_hour_ago]
    recent_volume = sum([l.get("quantity", 0) * l.get("price", 0) for l in recent_liqs])

    total_volume = sum([l.get("quantity", 0) * l.get("price", 0) for l in liquidations])
    avg_hourly_volume = total_volume / 24

    spike = recent_volume > avg_hourly_volume * 3  # 3x average

    # Net bias
    long_liq_volume = sum([l.get("quantity", 0) * l.get("price", 0) for l in long_liqs])
    short_liq_volume = sum([l.get("quantity", 0) * l.get("price", 0) for l in short_liqs])

    if long_liq_volume > short_liq_volume * 1.5:
        net_bias = "short"  # –ú–Ω–æ–≥–æ long liquidations = bearish
    elif short_liq_volume > long_liq_volume * 1.5:
        net_bias = "long"  # –ú–Ω–æ–≥–æ short liquidations = bullish
    else:
        net_bias = "neutral"

    return {
        "clusters_above": clusters_above,
        "clusters_below": clusters_below,
        "last_24h_liq_spike": spike,
        "spike_magnitude": "large" if recent_volume > avg_hourly_volume * 5 else "medium" if spike else "low",
        "net_liq_bias": net_bias
    }
```

---

### üî• –ì–ª–∞–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ #4: Dynamic Fear&Greed Weight

**–ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å `_analyze_market_context()`:**

```python
# –ó–∞–º–µ–Ω–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ 382-392 –Ω–∞:

# Fear & Greed bias (contrarian) - –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–ô –í–ï–°!
if fear_greed:
    fg_value = fear_greed.get("value", 50)

    # üîß DYNAMIC WEIGHT: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –∏ ADX
    base_weight = 1.0

    # –í–µ—Å –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º—É
    if timeframe in ["1d", "1w"]:
        tf_multiplier = 2.0  # –î–ª—è –±–æ–ª—å—à–∏—Ö TF –≤–µ—Å –≤—ã—à–µ
    elif timeframe in ["4h", "6h", "8h", "12h"]:
        tf_multiplier = 1.5  # –î–ª—è —Å—Ä–µ–¥–Ω–∏—Ö TF —Å—Ä–µ–¥–Ω–∏–π –≤–µ—Å
    else:
        tf_multiplier = 0.5  # –î–ª—è –º–∞–ª—ã—Ö TF (1h, 15m) –≤–µ—Å –Ω–∏–∂–µ

    # –°–Ω–∏–∂–∞–µ–º –≤–µ—Å –Ω–∞ —Å–∏–ª—å–Ω–æ–º —Ç—Ä–µ–Ω–¥–µ
    if adx and adx > 35:
        trend_multiplier = 0.5  # –ù–∞ —Å–∏–ª—å–Ω–æ–º —Ç—Ä–µ–Ω–¥–µ contrarian –æ–ø–∞—Å–Ω–µ–µ
    elif adx and adx > 25:
        trend_multiplier = 0.75
    else:
        trend_multiplier = 1.0

    final_weight = base_weight * tf_multiplier * trend_multiplier

    # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–µ—Å
    if fg_value < 20:  # Extreme Fear
        bias_score += round(3 * final_weight)
    elif fg_value < 30:  # Fear
        bias_score += round(2 * final_weight)
    elif fg_value > 80:  # Extreme Greed
        bias_score -= round(3 * final_weight)
    elif fg_value > 70:  # Greed
        bias_score -= round(2 * final_weight)
```

**–ù–æ –ø–æ—Å—Ç–æ–π—Ç–µ!** –í `_analyze_market_context()` –Ω–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ `timeframe`!

–ù—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å:
```python
def _analyze_market_context(
    self,
    price: float,
    klines: pd.DataFrame,
    indicators: Dict,
    funding: Optional[Dict],
    oi: Optional[Dict],
    ls_ratio: Optional[Dict],
    fear_greed: Optional[Dict],
    mtf_data: Dict[str, pd.DataFrame],
    timeframe: str  # üÜï ADD THIS!
) -> Dict[str, Any]:
```

---

### üî• –ì–ª–∞–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ #5: –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø–æ–ª—è –≤ output

**–ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∞–¥–∞–ø—Ç–∞—Ü–∏—é —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ (—Å—Ç—Ä–æ–∫–∏ 898-947):**

```python
# –î–æ–±–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏ 906:
# –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
entry_mid = (sc.get("entry", {}).get("price_min", 0) + sc.get("entry", {}).get("price_max", 0)) / 2
recommended_stop = sc.get("stop_loss", {}).get("recommended", 0)

# Stop % –æ—Ç entry
stop_pct_of_entry = abs((recommended_stop - entry_mid) / entry_mid) * 100 if entry_mid > 0 else 0

# ATR multiple stop
atr_multiple_stop = (entry_mid - recommended_stop) / atr if atr and atr > 0 else None

# Time valid hours (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞)
time_valid_hours_map = {
    "15m": 4,
    "1h": 6,
    "4h": 48,
    "1d": 168  # 1 week
}
time_valid_hours = time_valid_hours_map.get(timeframe, 24)

# Entry trigger (extract from conditions)
conditions = sc.get("conditions", [])
entry_trigger = conditions[0] if conditions else "Enter at specified price zone"

# No-trade conditions (extract from risks)
risks = sc.get("risks", [])
no_trade_conditions = [f"Avoid if {risk.lower()}" for risk in risks[:2]]

# –û–±–Ω–æ–≤–ª—è–µ–º adapted_sc:
adapted_sc = {
    "id": sc.get("id"),
    "name": sc.get("name"),
    "bias": sc.get("bias"),
    "confidence": sc.get("confidence"),
    "entry": sc.get("entry"),
    "stop_loss": sc.get("stop_loss"),
    "targets": sc.get("targets"),
    "leverage": adapted_leverage,
    "invalidation": adapted_invalidation,
    "why": adapted_why,
    "conditions": sc.get("conditions", []),

    # üÜï NEW FIELDS
    "stop_pct_of_entry": round(stop_pct_of_entry, 2),
    "atr_multiple_stop": round(atr_multiple_stop, 2) if atr_multiple_stop else None,
    "time_valid_hours": time_valid_hours,
    "entry_trigger": entry_trigger,
    "no_trade_conditions": no_trade_conditions
}
```

---

## üöÄ –ò—Ç–æ–≥–æ–≤—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### Phase 1: –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è (HIGH PRIORITY)

1. ‚úÖ **–î–æ–±–∞–≤–∏—Ç—å `_calculate_price_structure()`**
   - Swing points detection
   - Range calculation
   - Trend state by TF
   - Volatility regime

2. ‚úÖ **–î–æ–±–∞–≤–∏—Ç—å `_aggregate_liquidation_clusters()`**
   - Clusters above/below
   - Spike detection
   - Net bias

3. ‚úÖ **–ü–µ—Ä–µ–¥–µ–ª–∞—Ç—å –ø—Ä–æ–º–ø—Ç –Ω–∞ JSON —Ñ–æ—Ä–º–∞—Ç**
   - –°–æ–∑–¥–∞—Ç—å `market_data` dict
   - –ö–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç —Å JSON
   - –ü—Ä–∞–≤–∏–ª–æ "select from candidates, don't invent"

### Phase 2: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –≤–µ—Å–∞ (MEDIUM PRIORITY)

4. ‚úÖ **Dynamic Fear&Greed weight**
   - –î–æ–±–∞–≤–∏—Ç—å `timeframe` –≤ `_analyze_market_context()`
   - Multipliers –ø–æ TF –∏ ADX

5. ‚úÖ **–£–ª—É—á—à–∏—Ç—å –ª–æ–≥–∏–∫—É max_scenarios**
   - –ü—Ä–æ—Å–∏—Ç—å —Ä–æ–≤–Ω–æ `max_scenarios`
   - Post-filter: 1 long + 1 short + best neutral

### Phase 3: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π output (LOW PRIORITY)

6. ‚úÖ **–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø–æ–ª—è –≤ output**
   - stop_pct_of_entry
   - atr_multiple_stop
   - time_valid_hours
   - entry_trigger
   - no_trade_conditions

7. ‚úÖ **–î–æ–±–∞–≤–∏—Ç—å scenario_class**
   - primary / alternative / hedge
   - –í JSON schema –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏

---

## üí∞ –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –¢–æ—á–Ω–æ—Å—Ç—å
- ‚¨ÜÔ∏è **+15-20%** –±–ª–∞–≥–æ–¥–∞—Ä—è structure summary
- ‚¨ÜÔ∏è **+10-15%** –±–ª–∞–≥–æ–¥–∞—Ä—è liquidation clusters
- ‚¨ÜÔ∏è **+5-10%** –±–ª–∞–≥–æ–¥–∞—Ä—è dynamic F&G weight

### –°—Ç–æ–∏–º–æ—Å—Ç—å
- ‚¨áÔ∏è **-30-40%** tokens –±–ª–∞–≥–æ–¥–∞—Ä—è JSON –≤–º–µ—Å—Ç–æ —Ç–µ–∫—Å—Ç–∞
- ‚¨áÔ∏è **-20%** –±–ª–∞–≥–æ–¥–∞—Ä—è –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–æ–º—É –ø—Ä–æ–º–ø—Ç—É

### –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
- ‚¨áÔ∏è **-50%** –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –±–ª–∞–≥–æ–¥–∞—Ä—è "select from candidates"
- ‚¨ÜÔ∏è **+90%** consistency –±–ª–∞–≥–æ–¥–∞—Ä—è structured data

---

## üìù –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–¥–µ–∏ (–¥–ª—è –±—É–¥—É—â–µ–≥–æ)

### 2-Stage Approach (Advanced)

**Stage 1: Rule-based calculation (Python)**
```python
def _calculate_scenario_candidates(self, ...):
    """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–∞ entry/stop/targets –ë–ï–ó LLM"""

    candidates = {
        "long_entries": [
            {"price": support_1, "type": "support_bounce", "confidence_base": 0.6},
            {"price": ema_20, "type": "ema_pullback", "confidence_base": 0.7},
            {"price": resistance_break, "type": "breakout", "confidence_base": 0.5}
        ],
        "long_stops": [
            {"price": support_1 - atr, "type": "below_support_1atr"},
            {"price": swing_low, "type": "below_swing_low"}
        ],
        "long_targets": [
            {"price": resistance_1, "type": "first_resistance", "rr": 2.0},
            {"price": resistance_2, "type": "major_resistance", "rr": 4.0}
        ]
    }

    return candidates
```

**Stage 2: LLM reasoning (AI)**
```python
prompt = f"""You have pre-calculated scenario candidates.
Your job: select best combinations and explain reasoning.

CANDIDATES (JSON):
{json.dumps(candidates)}

Select 3 scenarios and explain WHY each is valid.
"""
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- LLM –Ω–µ "–ø—Ä–∏–¥—É–º—ã–≤–∞–µ—Ç" —Ü–µ–Ω—ã
- –î–µ—à–µ–≤–ª–µ (–º–µ–Ω—å—à–µ —Ä–∞–±–æ—Ç—ã –¥–ª—è LLM)
- –°—Ç–∞–±–∏–ª—å–Ω–µ–µ (–≤—Å–µ —Ü–µ–Ω—ã –≤–∞–ª–∏–¥–Ω—ã–µ)

---

## üéØ –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

–ü–æ—Å–ª–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —É–ª—É—á—à–µ–Ω–∏–π, —Å—Ä–∞–≤–Ω–∏—Ç—å:

1. **Accuracy:** Win rate —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ (TP1/TP2/TP3 hit rate)
2. **Cost:** Average tokens per request
3. **Stability:** Variance –≤ confidence scores
4. **Speed:** Response time

**–¶–µ–ª—å:**
- Accuracy: 60% ‚Üí 75% (TP1 hit rate)
- Cost: $0.05 ‚Üí $0.03 per request
- Stability: stdev(confidence) < 0.1

---

## ‚úÖ Checklist –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

- [ ] –°–æ–∑–¥–∞—Ç—å `_calculate_price_structure()`
- [ ] –°–æ–∑–¥–∞—Ç—å `_aggregate_liquidation_clusters()`
- [ ] –ü–µ—Ä–µ–¥–µ–ª–∞—Ç—å –ø—Ä–æ–º–ø—Ç –Ω–∞ JSON —Ñ–æ—Ä–º–∞—Ç
- [ ] –î–æ–±–∞–≤–∏—Ç—å `timeframe` –≤ `_analyze_market_context()`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å dynamic Fear&Greed weight
- [ ] –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø–æ–ª—è –≤ output
- [ ] –û–±–Ω–æ–≤–∏—Ç—å JSON schema —Å scenario_class
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å unit tests
- [ ] A/B —Ç–µ—Å—Ç: —Å—Ç–∞—Ä–∞—è vs –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è
- [ ] Deploy –≤ production

---

## üîó –°–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã

- [FUTURES_TRADING_API.md](./FUTURES_TRADING_API.md)
- [FUTURES_API_FINAL_SUMMARY.md](./FUTURES_API_FINAL_SUMMARY.md)
- [PROMPT_ENGINEERING_ANALYSIS_2025.md](./PROMPT_ENGINEERING_ANALYSIS_2025.md)

---

**–°—Ç–∞—Ç—É—Å:** üìã –ü–ª–∞–Ω –≥–æ—Ç–æ–≤ –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ HIGH (–≤–ª–∏—è–µ—Ç –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å)
**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Phase 1
