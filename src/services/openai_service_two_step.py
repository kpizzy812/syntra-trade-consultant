# coding: utf-8
"""
Two-Step OpenAI Service: Analysis ‚Üí Styling

This service separates data analysis from personality styling to maximize Syntra's character.

Architecture:
1. Step 1: Data Analysis (GPT-4o-mini)
   - Execute function calls to get crypto data
   - Structured analysis without personality
   - Fast and cost-effective

2. Step 2: Styling with Persona (GPT-4o)
   - Apply full Syntra personality to analysis
   - Dynamic sarcasm mode
   - Catchphrases and character enforcement
   - Creative and engaging

Benefits:
- ‚úÖ Better personality preservation
- ‚úÖ More consistent character
- ‚úÖ Cleaner separation of concerns
- ‚úÖ Higher quality responses
- ‚ö†Ô∏è Slightly higher cost (but worth it)
"""
import json
from typing import AsyncGenerator, List, Dict, Any

from sqlalchemy.ext.asyncio import AsyncSession

from config.config import ModelConfig
from config.prompt_selector import get_system_prompt
from src.database.crud import add_chat_message, get_chat_history, track_cost
from src.services.openai_service import OpenAIService
from src.services.crypto_tools import CRYPTO_TOOLS, execute_tool


from loguru import logger


class TwoStepOpenAIService(OpenAIService):
    """
    Two-step AI service: Analysis ‚Üí Styling

    Optimized for maximum personality preservation
    """

    # Data collection prompt - ONLY JSON, no analysis
    ANALYSIS_SYSTEM_PROMPT = """
You are a crypto data collector. Your ONLY job: call tools, return raw data as JSON.

# CRITICAL RULES:
1. **ALWAYS call relevant tools first** - NEVER respond without calling tools
2. **ALWAYS return ONLY JSON** - zero text, zero comments, zero analysis
3. **NO conclusions** - just raw data from tools
4. **NO interpretation** - Step 2 (smarter model) will do ALL analysis
5. **NEVER say "I need data"** - YOU must call tools to get data yourself

You are a task runner. Fetch data ‚Üí Format as JSON ‚Üí Done.

# TOOL SELECTION:

## Market Overview / Risk-Reward Questions
User asks: "—á—Ç–æ –ø–æ —Ä—ã–Ω–∫—É", "market overview", "–≥–¥–µ –±–æ–ª—å—à–µ —Ä–∏—Å–∫ —Ä–µ–≤–∞—Ä–¥", "what's the best RR"
‚Üí CALL: get_market_overview()
‚Üí RETURN: exact JSON from tool (btc, eth, alts, market, news)

## Specific Coin Trading Questions
User asks: "long/short ETH?", "BTC –¥–æ 100–∫?", "ARB –Ω–æ—Ä–º —Ç–µ–º–∞?"
‚Üí CALL: get_technical_analysis(coin_id, timeframe)
  - timeframe: "1d" for swing, "4h" for day trade, "1h" for scalping
‚Üí RETURN: {
  "coin_id": "...",
  "price": ...,
  "change_24h": ...,
  "technical_indicators": {...},  // RSI, MACD, EMA, ATR
  "scenario_levels": {...},       // entry/SL/TP levels
  "support_resistance": {...},    // S/R levels, liquidity zones
  "fibonacci_levels": {...},      // fib retracement
  "funding_data": {...},          // funding rate, sentiment (if available)
  "long_short_data": {...},       // L/S ratio, sentiment (if available)
  "cycle_data": {...},            // rainbow chart (BTC only)
  "extended_market_data": {...},  // ATH/ATL, market cap, volume
  "candles": {...},               // multi-timeframe OHLCV data
  "news": [...]                   // latest news (if available)
}

## Quick Price Check
User asks: "—Ü–µ–Ω–∞ SOL", "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç BTC"
‚Üí CALL: get_crypto_price(coin_id)
‚Üí RETURN: {"coin_id": "...", "price": ..., "change_24h": ..., "market_cap": ..., "volume": ...}

## News Questions
User asks: "–Ω–æ–≤–æ—Å—Ç–∏ BTC", "—á—Ç–æ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ Ethereum"
‚Üí CALL: get_crypto_news(coin_id)
‚Üí RETURN: {"coin_id": "...", "news": [...]}

## DEX Token Analysis
User asks about low-cap/DEX token: "—á—Ç–æ —Å BONK", "–∫–∞–∫ —Ç–∞–º PEPE"
‚Üí CALL: get_dex_token_info(token_address, chain)
‚Üí RETURN: {
  "address": "...",
  "price": ...,
  "liquidity": ...,
  "volume_24h": ...,
  "price_change_5m": ...,
  "price_change_1h": ...,
  "price_change_6h": ...,
  "price_change_24h": ...,
  "txns": {...},
  "holders": ...
}

# SCAM DETECTION:
If token has ALL these flags:
- Liquidity < $1,000
- Volume 24h < $500
- No market cap data
‚Üí RETURN: {"error": "scam_detected", "reason": "liquidity <$1k, volume <$500, likely honeypot/rug"}

# USER CONTEXT EXTRACTION:
If user mentions team/events/roadmap/position:
‚Üí ADD to JSON: {
  "user_context": {
    "mentioned_team": "...",
    "mentioned_events": "...",
    "user_position": "...",  // entry price, P&L if mentioned
    "concerns": "..."
  }
}

# OUTPUT FORMAT:
ALWAYS return pure JSON. No text before/after. Example:

{
  "data_type": "technical_analysis",
  "coin_id": "ethereum",
  "price": 3120,
  "technical_indicators": {...},
  "scenario_levels": {...},
  ...
}

If get_market_overview():
{
  "data_type": "market_overview",
  "btc": {...},
  "eth": {...},
  "alts": [...],
  "market": {...},
  "news": [...]
}

# SPECIAL CASES:
If user asks general question (not about specific crypto/market):
{
  "data_type": "general_question",
  "question": "user question text",
  "context": "any relevant context from history"
}

If tools fail or data unavailable:
{
  "data_type": "error",
  "error": "brief error description",
  "fallback_data": {...}  // any partial data you got
}

NO comments. NO explanations. NO text like "I need data" or "Please provide". ONLY JSON.
"""

    async def stream_two_step_completion(
        self,
        session: AsyncSession,
        user_id: int,
        user_message: str,
        user_language: str = "ru",
        user_tier: str = "free",
        max_tool_iterations: int = 5,
    ) -> AsyncGenerator[str, None]:
        """
        Two-step streaming completion with enhanced personality (tier-aware)

        Step 1: Get data with function calling (mini model, no personality)
        Step 2: Style response with full Syntra persona (4o model, max creativity)

        Tier-based Memory:
        - FREE: 0 messages (no memory)
        - BASIC: 5 messages
        - PREMIUM: 10 messages
        - VIP: 50 messages

        Args:
            session: Database session
            user_id: User's database ID
            user_message: User's message
            user_language: User's language ('ru' or 'en')
            user_tier: User's subscription tier (free, basic, premium, vip)
            max_tool_iterations: Max function calling iterations

        Yields:
            Text chunks from final styled response
        """
        from config.limits import get_chat_history_limit, should_save_chat_history
        from src.database.models import SubscriptionTier

        try:
            # Get tier enum
            try:
                tier_enum = SubscriptionTier(user_tier)
            except ValueError:
                logger.warning(f"Invalid tier '{user_tier}', defaulting to FREE")
                tier_enum = SubscriptionTier.FREE

            # Get history limit for tier
            max_history = get_chat_history_limit(tier_enum)

            logger.info(
                f"üé¨ Two-step process started for user {user_id} (tier={user_tier}, history_limit={max_history}): {user_message[:50]}..."
            )

            # Save user message to history (only for tiers with save_chat_history=True)
            if should_save_chat_history(tier_enum):
                await add_chat_message(
                    session, user_id=user_id, role="user", content=user_message
                )
                logger.debug(f"User message saved to history for tier {user_tier}")
            else:
                logger.debug(
                    f"User message NOT saved to history for tier {user_tier} (save_chat_history=False)"
                )

            # ==========================================
            # STEP 1: DATA ANALYSIS (mini, no personality)
            # ==========================================

            logger.info("üìä Step 1: Analyzing data with function calling...")

            # Get recent chat history for context (tier-aware)
            history = []
            if max_history > 0:
                history = await get_chat_history(session, user_id, limit=max_history)
                logger.info(f"Loaded {len(history)} messages from history")
            else:
                logger.info(f"No history loaded for FREE tier")

            # Build analysis messages with context
            analysis_messages: List[Dict[str, Any]] = [
                {"role": "system", "content": self.ANALYSIS_SYSTEM_PROMPT}
            ]

            # Add recent history for context
            # If we saved current message (paid tiers), exclude it from history
            # If we didn't save (FREE tier), use all history
            history_to_use = history[:-1] if should_save_chat_history(tier_enum) and len(history) > 0 else history
            for msg in history_to_use:
                analysis_messages.append({
                    "role": msg.role,
                    "content": msg.content
                })

            # Add current user message
            analysis_messages.append({"role": "user", "content": user_message})

            step1_input_tokens = 0
            step1_output_tokens = 0
            tool_calls_made = []
            structured_analysis = ""

            # Iterative function calling loop
            iteration = 0
            while iteration < max_tool_iterations:
                iteration += 1

                # Use mini for data gathering (cost-effective)
                response = await self.openai_client.chat.completions.create(
                    model=ModelConfig.GPT_4O_MINI,
                    messages=analysis_messages,
                    tools=CRYPTO_TOOLS,
                    tool_choice="auto",
                    max_tokens=800,  # Enough for structured analysis
                    temperature=0.3,  # Low temperature for factual analysis
                )

                message = response.choices[0].message

                # Track tokens
                if response.usage:
                    step1_input_tokens += response.usage.prompt_tokens
                    step1_output_tokens += response.usage.completion_tokens

                # Check if AI wants to call tools
                if message.tool_calls:
                    logger.info(f"üîß AI requested {len(message.tool_calls)} tool calls")

                    # Add assistant message with tool calls
                    analysis_messages.append({
                        "role": "assistant",
                        "content": message.content,
                        "tool_calls": [
                            {
                                "id": tc.id,
                                "type": "function",
                                "function": {
                                    "name": tc.function.name,
                                    "arguments": tc.function.arguments,
                                },
                            }
                            for tc in message.tool_calls
                        ],
                    })

                    # Execute tools
                    for tool_call in message.tool_calls:
                        tool_name = tool_call.function.name
                        tool_id = tool_call.id

                        try:
                            arguments = json.loads(tool_call.function.arguments)
                            logger.info(f"‚öôÔ∏è Executing: {tool_name}({arguments})")

                            result = await execute_tool(tool_name, arguments)

                            # –õ–æ–≥–∏—Ä—É–µ–º —á—Ç–æ –≤–µ—Ä–Ω—É–ª tool
                            logger.info(f"üì¶ Tool {tool_name} result: {len(result)} chars")
                            try:
                                result_data = json.loads(result)
                                if result_data.get('success'):
                                    data_sources = result_data.get('data_sources', [])
                                    logger.info(f"   ‚úÖ Data sources: {data_sources}")
                                    if 'funding_data' in result_data and result_data['funding_data']:
                                        logger.info(f"   üí∞ Funding: {result_data['funding_data']}")
                                    if 'long_short_data' in result_data and result_data['long_short_data']:
                                        logger.info(f"   üìà L/S Ratio: {result_data['long_short_data']}")
                                    if 'cycle_data' in result_data and result_data['cycle_data']:
                                        logger.info(f"   üåà Cycle: {result_data['cycle_data'].get('current_band')}")
                            except:
                                pass

                            analysis_messages.append({
                                "role": "tool",
                                "tool_call_id": tool_id,
                                "content": result,
                            })

                            tool_calls_made.append({
                                "name": tool_name,
                                "arguments": arguments,
                            })

                        except Exception as e:
                            logger.error(f"‚ùå Tool execution failed: {e}")
                            analysis_messages.append({
                                "role": "tool",
                                "tool_call_id": tool_id,
                                "content": json.dumps({"success": False, "error": str(e)}),
                            })

                    # Continue to next iteration
                    continue

                else:
                    # No more tools - AI provided structured analysis
                    structured_analysis = message.content or ""
                    logger.info(f"‚úÖ Step 1 complete. Analysis: {len(structured_analysis)} chars")
                    logger.info(f"üìù STRUCTURED ANALYSIS:\n{structured_analysis}\n{'='*80}")
                    break

            # ==========================================
            # STEP 2: STYLING WITH SYNTRA PERSONA (4o, full creativity)
            # ==========================================

            logger.info("üé® Step 2: Styling with Syntra persona...")

            # Build persona prompt with dynamic sarcasm detection
            syntra_system_prompt = get_system_prompt(
                user_language,
                user_message=user_message  # Auto-detect sarcasm mode
            )

            # Detect if user mentioned losses/drawdown for SAFEGUARD
            # –í–ê–ñ–ù–û: –ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ "-" –∫–∞–∫ —Ç—Ä–∏–≥–≥–µ—Ä (–ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ "BTC -5%")
            # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω "–≤ –º–∏–Ω—É—Å–µ -X%" –∏–ª–∏ "–º–∏–Ω—É—Å X%"
            import re
            loss_percentage_pattern = r'(–≤ –º–∏–Ω—É—Å–µ|–º–∏–Ω—É—Å|—É–±—ã—Ç–æ–∫).{0,5}[-\d]+%'
            has_loss_percentage = bool(re.search(loss_percentage_pattern, user_message.lower()))

            user_has_losses = has_loss_percentage or any(trigger in user_message.lower() for trigger in [
                "–ø—Ä–æ—Å–∞–¥–∫–∞", "—É–±—ã—Ç–æ–∫", "–≤ –º–∏–Ω—É—Å–µ", "–ø–æ—Ç–µ—Ä—è–ª", "—Å–ª–∏–ª", "–ª–∏–∫–≤–∏–¥–Ω—É–ª–∏",
                "–æ–±–Ω—É–ª–∏–ª—Å—è", "–ø–æ—Ç–µ—Ä—è–ª –≤—Å—ë", "–ø–∞–Ω–∏–∫–∞", "—Å—Ç—Ä–∞—à–Ω–æ", "–±–æ—é—Å—å"
            ])

            safeguard_instruction = ""
            if user_has_losses:
                safeguard_instruction = """
‚ö†Ô∏è SAFEGUARD MODE: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–ø–æ–º—è–Ω—É–ª —É–±—ã—Ç–∫–∏ –∏–ª–∏ –ø—Ä–æ—Å–∞–¥–∫—É.
- –ü–û–õ–ù–û–°–¢–¨–Æ —É–±–µ—Ä–∏ —Å–∞—Ä–∫–∞–∑–º –∏ –∏—Ä–æ–Ω–∏—é
- –ì–æ–≤–æ—Ä–∏ —Å–ø–æ–∫–æ–π–Ω–æ, —Ä–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–µ
- –§–æ–∫—É—Å –Ω–∞ –ø–æ–º–æ—â–∏ –ø—Ä–∏–Ω—è—Ç—å –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
"""

            # Detect if this is a market overview question
            is_market_overview = any(keyword in user_message.lower() for keyword in [
                "–ø–æ —Ä—ã–Ω–∫—É", "—Ä—ã–Ω–æ–∫", "—á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç", "–∫–∞–∫ –∫—Ä–∏–ø—Ç–∞", "market",
                "–æ–±–∑–æ—Ä —Ä—ã–Ω–∫–∞", "–æ–±—â–∞—è —Å–∏—Ç—É–∞—Ü–∏—è", "–æ–±—â–∏–π —Ç—Ä–µ–Ω–¥"
            ])

            # Detect if this is a newbie question (educational)
            is_newbie_question = any(keyword in user_message.lower() for keyword in [
                "—á—Ç–æ —Ç–∞–∫–æ–µ", "—á—Ç–æ –∑–Ω–∞—á–∏—Ç", "–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç", "–æ–±—ä—è—Å–Ω–∏", "–Ω–µ –ø–æ–Ω–∏–º–∞—é",
                "—Ä–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ", "–∑–∞—á–µ–º –Ω—É–∂–µ–Ω", "–≤ —á—ë–º —Ä–∞–∑–Ω–∏—Ü–∞", "–¥–ª—è —á–µ–≥–æ",
                "what is", "what does", "how does", "explain"
            ])

            # Detect if this is a trading question (specific coin analysis)
            # –í–∫–ª—é—á–∞–µ–º —Ç–∞–∫–∂–µ –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–æ –ø—Ä–æ—Å–∞–¥–∫–∏/hold/sell
            is_trading_question = any(keyword in user_message.lower() for keyword in [
                "–ª–æ–Ω–≥", "—à–æ—Ä—Ç", "long", "short", "–≤–∑—è—Ç—å", "–∑–∞–π—Ç–∏", "–∫—É–ø–∏—Ç—å", "–ø—Ä–æ–¥–∞—Ç—å",
                "–ª–æ–Ω–≥–æ–≤–∞—Ç—å", "—à–æ—Ä—Ç–∏—Ç—å", "–¥–æ–∫–∞—Ç–∏—Ç –¥–æ", "–¥–æ–π–¥–µ—Ç –¥–æ", "—Ä–∞—Å–∫–ª–∞–¥",
                "—Å—Ç–æ–∏—Ç –ª–∏ –±—Ä–∞—Ç—å", "–∏–º–µ–µ—Ç —Å–º—ã—Å–ª", "–Ω–æ—Ä–º —Ç–µ–º–∞",
                "–¥–µ—Ä–∂–∞—Ç—å", "—Ñ–∏–∫—Å–∏—Ç—å", "—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å", "–ø—Ä–æ–¥–∞–≤–∞—Ç—å", "–≤—ã—Ö–æ–¥–∏—Ç—å",
                "–≤ –º–∏–Ω—É—Å–µ", "–ø—Ä–æ—Å–∞–¥–∫–∞", "—É–±—ã—Ç–æ–∫", "hold", "sell"
            ]) and any(coin in user_message.lower() for coin in [
                "btc", "eth", "–±–∏—Ç–æ–∫", "—ç—Ñ–∏—Ä", "bitcoin", "ethereum", "—Å–æ–ª–∞–Ω–∞", "solana",
                "bnb", "xrp", "ada", "dot", "doge", "shib", "avax", "matic", "link", "uni",
                "–∞—Ä–±", "arb", "arbitrum", "op", "optimism"
            ])

            # Create styling prompt based on question type
            if is_trading_question:
                styling_prompt = f"""
–¢—ã –ø–æ–ª—É—á–∏–ª –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ –º–æ–Ω–µ—Ç–µ:

{structured_analysis}

{safeguard_instruction}

‚ö° –¢–í–û–Ø –ó–ê–î–ê–ß–ê ‚Äî –ü–†–û–ê–ù–ê–õ–ò–ó–ò–†–û–í–ê–¢–¨ –ò –î–ê–¢–¨ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Æ:

–í–ê–ñ–ù–û: –ù–ò–ö–û–ì–î–ê –Ω–µ —É–ø–æ–º–∏–Ω–∞–π "JSON", "data collector", "–¥–∞–Ω–Ω—ã–µ", "—Å—Ç—Ä—É–∫—Ç—É—Ä—É" –∏–ª–∏ –ª—é–±—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã –≤ –æ—Ç–≤–µ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
–û—Ç–≤–µ—á–∞–π —Ç–∞–∫, –±—É–¥—Ç–æ —Ç—ã –í–°–ï–ì–î–ê –∏–º–µ–ª –¥–æ—Å—Ç—É–ø –∫ —ç—Ç–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.

–ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (RSI, MACD, EMA, ATR)
- –£—Ä–æ–≤–Ω–∏ –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞ –∏ —Å—Ç–æ–ø-–ª–æ—Å—Å–æ–≤
- –£—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è
- –î–∞–Ω–Ω—ã–µ –ø–æ —Ñ–∞–Ω–¥–∏–Ω–≥—É –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è–º —Ä—ã–Ω–∫–∞
- –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ª–æ–Ω–≥–æ–≤/—à–æ—Ä—Ç–æ–≤
- –§–∞–∑–∞ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ (–¥–ª—è BTC)
- –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (ATH/ATL, –æ–±—ä–µ–º—ã)

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –¥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é.

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–∞–¥–∞–ø—Ç–∏—Ä—É–π –ø–æ–¥ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è):

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –ï–°–¢–ï–°–¢–í–ï–ù–ù–û, –∫–∞–∫ Syntra - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–æ–º:

1. **–ü–†–Ø–ú–û–ô –û–¢–í–ï–¢**:
   - –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ long/short ‚Üí –¥–∞–π bias —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º –∏–∑ –¥–∞–Ω–Ω—ã—Ö
   - –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ "–¥–µ—Ä–∂–∞—Ç—å –∏–ª–∏ –ø—Ä–æ–¥–∞—Ç—å" ‚Üí –¥–∞–π –∞–Ω–∞–ª–∏–∑ —Å–∏—Ç—É–∞—Ü–∏–∏ –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏
   - –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å "–¥–æ–π–¥–µ—Ç –¥–æ $X" ‚Üí —Ä–∞—Å—Å—á–∏—Ç–∞–π –ø—É—Ç—å –ø–æ —É—Ä–æ–≤–Ω—è–º —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
   - –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –ø—Ä–æ—Å–∞–¥–∫—É ‚Üí –æ—Ü–µ–Ω–∏ —Ç–µ–∫—É—â—É—é —Å–∏—Ç—É–∞—Ü–∏—é –∏ —Ä–∏—Å–∫–∏

2. **–°–¶–ï–ù–ê–†–ò–ò** (–µ—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ):
   - –ë—ã—á–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–π —Å —É—Å–ª–æ–≤–∏—è–º–∏ –∏ —É—Ä–æ–≤–Ω—è–º–∏
   - –ú–µ–¥–≤–µ–∂–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–π —Å —É—Å–ª–æ–≤–∏—è–º–∏ –∏ —É—Ä–æ–≤–Ω—è–º–∏
   - –ò—Å–ø–æ–ª—å–∑—É–π –¥–∞–Ω–Ω—ã–µ: RSI, funding, S/R —É—Ä–æ–≤–Ω–∏, –æ–±—ä–µ–º—ã

3. **–í–´–í–û–î**: –¢–≤–æ—è —á—ë—Ç–∫–∞—è –ø–æ–∑–∏—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞

4. **–ö–û–ù–ö–†–ï–¢–ò–ö–ê**: –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã ($, %, RSI, funding)

‚ö†Ô∏è –ó–ê–ü–†–ï–©–ï–ù–û —É–ø–æ–º–∏–Ω–∞—Ç—å –≤ –æ—Ç–≤–µ—Ç–µ: "JSON", "–¥–∞–Ω–Ω—ã–µ –æ—Ç data collector", "structured_analysis", "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ", –∏–ª–∏ –ª—é–±—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ —Å–∏—Å—Ç–µ–º—ã.

–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –∂–µ—Å—Ç–∫–∏–µ —à–∞–±–ª–æ–Ω—ã. –û—Ç–≤–µ—á–∞–π –∫–∞–∫ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–æ–º Syntra.

–î–æ–±–∞–≤—å –≤ –∫–æ–Ω—Ü–µ: ‚ö° NFA

–í–æ–ø—Ä–æ—Å: "{user_message}"
"""
            elif is_market_overview:
                styling_prompt = f"""
–¢—ã –ø–æ–ª—É—á–∏–ª –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ —Ä—ã–Ω–∫—É:

{structured_analysis}

{safeguard_instruction}

‚ö° –¢–í–û–Ø –ó–ê–î–ê–ß–ê ‚Äî –ü–†–û–ê–ù–ê–õ–ò–ó–ò–†–û–í–ê–¢–¨ –†–´–ù–û–ö –ò –î–ê–¢–¨ –í–´–í–û–î–´:

–í–ê–ñ–ù–û: –ù–ò–ö–û–ì–î–ê –Ω–µ —É–ø–æ–º–∏–Ω–∞–π "JSON", "data collector", "–¥–∞–Ω–Ω—ã–µ", –∏–ª–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ.

–ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª—É—á–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:
- BTC: —Ü–µ–Ω–∞, –∏–∑–º–µ–Ω–µ–Ω–∏–µ, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç ATH, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
- BTC: —É—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è, —Ñ–∞–Ω–¥–∏–Ω–≥, long/short ratio
- BTC: —Ñ–∞–∑–∞ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ (Rainbow Chart)
- ETH: —Ü–µ–Ω–∞, –∏–∑–º–µ–Ω–µ–Ω–∏–µ, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç ATH
- –ê–ª—å—Ç–∫–æ–∏–Ω—ã: –º–∞—Å—Å–∏–≤ –º–æ–Ω–µ—Ç —Å —Ü–µ–Ω–∞–º–∏ –∏ –ø—Ä–æ—Å–∞–¥–∫–∞–º–∏ –æ—Ç ATH
- –†—ã–Ω–æ–∫: –¥–æ–º–∏–Ω–∞—Ü–∏—è BTC/ETH/–∞–ª—å—Ç–æ–≤, –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏
- –ù–æ–≤–æ—Å—Ç–∏: –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è –Ω–∞ —Ä—ã–Ω–∫–µ

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ —Å–¥–µ–ª–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –≤—ã–≤–æ–¥—ã.

–§–û–†–ú–ê–¢ (–¥–ª—è market overview):
- 2-3 —Å—Ç—Ä–æ–∫–∏: –æ–±—â–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ (dominance, F&G, trend) + —Ç–≤–æ–π –≤—ã–≤–æ–¥
- 2-3 —Å—Ç—Ä–æ–∫–∏: BTC (—Ü–µ–Ω–∞, RSI, —É—Ä–æ–≤–Ω–∏, funding) + –∫—É–¥–∞ –¥–≤–∏–∂–µ—Ç—Å—è
- 1-2 —Å—Ç—Ä–æ–∫–∏: –∞–ª—å—Ç—ã/ETH + —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å BTC
- 1 —Å—Ç—Ä–æ–∫–∞: —Ü–∏–Ω–∏—á–Ω—ã–π –≤—ã–≤–æ–¥

–§–û–†–ú–ê–¢ (–¥–ª—è risk/reward –≤–æ–ø—Ä–æ—Å–æ–≤):
- –†–∞–∑–±–µ–π –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º: BTC / ETH / Alts
- –î–ª—è –∫–∞–∂–¥–æ–≥–æ: % –æ—Ç ATH ‚Üí –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–æ ATH ‚Üí RR –æ—Ü–µ–Ω–∫–∞
- –í—ã–≤–æ–¥: –≥–¥–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π RR –∏ –ø–æ—á–µ–º—É

–ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏ –¥–∞–Ω–Ω—ã–µ.

‚ö†Ô∏è –ó–ê–ü–†–ï–©–ï–ù–û —É–ø–æ–º–∏–Ω–∞—Ç—å: "JSON", "–¥–∞–Ω–Ω—ã–µ", "data collector", "–¥–æ–∫—É–º–µ–Ω—Ç", –∏–ª–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ —Å–∏—Å—Ç–µ–º—ã.

–î–æ–±–∞–≤—å –≤ –∫–æ–Ω—Ü–µ: ‚ö° NFA

–í–æ–ø—Ä–æ—Å: "{user_message}"
"""
            elif is_newbie_question:
                styling_prompt = f"""
–í–æ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫–∞:

{structured_analysis}

{safeguard_instruction}

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–æ–≤–∏—á–∫–∞ –≤ —Å—Ç–∏–ª–µ Syntra, –∏—Å–ø–æ–ª—å–∑—É—è –¥–∞–Ω–Ω—ã–µ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞.

üí¨ **–ü–ò–®–ò –ü–†–û–°–¢–û –ò –ü–û–ù–Ø–¢–ù–û**:
- –û–±—ä—è—Å–Ω—è–π —Ç–µ—Ä–º–∏–Ω—ã –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º, –±–µ–∑ –∂–∞—Ä–≥–æ–Ω–∞
- –ò—Å–ø–æ–ª—å–∑—É–π –∞–Ω–∞–ª–æ–≥–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –∂–∏–∑–Ω–∏
- –ù–ï –ø–µ—Ä–µ–≥—Ä—É–∂–∞–π —Ç–µ—Ä–º–∏–Ω–∞–º–∏ (RSI, MACD, Fibonacci –∏ —Ç–¥) ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ —Å–∞–º –≤–æ–ø—Ä–æ—Å
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç: —Å—É—Ç—å ‚Üí –ø—Ä–∏–º–µ—Ä ‚Üí –∑–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ

‚úÖ **–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û**:
1. **–ü–†–Ø–ú–û–ô –û–¢–í–ï–¢**: –î–∞–π –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ/–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–æ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)

2. **–ü–†–ò–ú–ï–†**: –ü–æ–∫–∞–∂–∏ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ —Å —Ü–µ–Ω–∞–º–∏

3. **–ü–†–ê–ö–¢–ò–ö–ê**: –ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ —Ç—Ä–µ–π–¥–µ—Ä—É / –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

4. **–°–¢–ò–õ–¨**: –õ—ë–≥–∫–∞—è –∏—Ä–æ–Ω–∏—è –¥–æ–ø—É—Å—Ç–∏–º–∞, –Ω–æ –±–µ–∑ –≤—ã—Å–æ–∫–æ–º–µ—Ä–∏—è. –¢—ã –æ–±—É—á–∞–µ—à—å, –∞ –Ω–µ —Å—Ç–µ–±—ë—à—å—Å—è –Ω–∞–¥ –Ω–æ–≤–∏—á–∫–æ–º.

5. –î–æ–±–∞–≤—å –≤ –∫–æ–Ω—Ü–µ: ‚ö° NFA (–µ—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ)

–ò—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å: "{user_message}"
"""
            else:
                styling_prompt = f"""
–¢—ã –ø–æ–ª—É—á–∏–ª –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:

{structured_analysis}

{safeguard_instruction}

‚ö° –¢–í–û–Ø –ó–ê–î–ê–ß–ê ‚Äî –ü–†–û–ê–ù–ê–õ–ò–ó–ò–†–û–í–ê–¢–¨ –ò –î–ê–¢–¨ –û–¢–í–ï–¢:

–í–ê–ñ–ù–û: –ù–ò–ö–û–ì–î–ê –Ω–µ —É–ø–æ–º–∏–Ω–∞–π "JSON", "–¥–∞–Ω–Ω—ã–µ", "data collector" –∏–ª–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.

–ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª—É—á–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:
- –¶–µ–Ω–∞, –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ 24—á, –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è, –æ–±—ä–µ–º, –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (–µ—Å–ª–∏ –µ—Å—Ç—å): RSI, MACD, EMA
- –£—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è, —É—Ä–æ–≤–Ω–∏ –§–∏–±–æ–Ω–∞—á—á–∏
- –£—Ä–æ–≤–Ω–∏ –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞ –∏ —Å—Ç–æ–ø-–ª–æ—Å—Å–æ–≤
- –ö–æ–Ω—Ç–µ–∫—Å—Ç: –∫–æ–º–∞–Ω–¥–∞, —Å–æ–±—ã—Ç–∏—è, roadmap, –ø–æ–∑–∏—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –ù–æ–≤–æ—Å—Ç–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è —Ä—ã–Ω–∫–∞

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –¥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é.

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:

–û—Ç–≤–µ—á–∞–π –ï–°–¢–ï–°–¢–í–ï–ù–ù–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —à–∞–±–ª–æ–Ω—ã —Ç–∏–ø–∞ "–î–µ—Ä–∂–∞—Ç—å/–§–∏–∫—Å–∏—Ç—å".
–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –í–û–ü–†–û–°–£:
- –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –ø—Ä–æ —Ü–µ–Ω—É ‚Üí –¥–∞–π –∞–Ω–∞–ª–∏–∑ —Ü–µ–Ω—ã –∏ —Ç—Ä–µ–Ω–¥–∞
- –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –ø—Ä–æ —É—Ä–æ–≤–Ω–∏ ‚Üí –¥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º
- –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –ø—Ä–æ —Ä–∏—Å–∫–∏ ‚Üí –æ—Ü–µ–Ω–∏ —Ä–∏—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö
- –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –ø—Ä–æ –¥–µ–π—Å—Ç–≤–∏—è (–¥–µ—Ä–∂–∞—Ç—å/–ø—Ä–æ–¥–∞—Ç—å) ‚Üí –¥–∞–π –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å —É—Å–ª–æ–≤–∏—è–º–∏

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
1. **–ö–û–ù–ö–†–ï–¢–ò–ö–ê**: –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã ($, %, RSI, –æ–±—ä—ë–º—ã)
2. **–í–´–í–û–î**: –ß—ë—Ç–∫–∞—è –∏—Ç–æ–≥–æ–≤–∞—è –ø–æ–∑–∏—Ü–∏—è –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ
3. –î–æ–±–∞–≤—å –≤ –∫–æ–Ω—Ü–µ: ‚ö° NFA

‚ö†Ô∏è –ó–ê–ü–†–ï–©–ï–ù–û —É–ø–æ–º–∏–Ω–∞—Ç—å: "JSON", "–¥–∞–Ω–Ω—ã–µ –æ—Ç collector", "–≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–µ—Ç", "–º–Ω–µ –Ω–µ—á–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", –∏–ª–∏ –ª—é–±—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ —Å–∏—Å—Ç–µ–º—ã.

–í–æ–ø—Ä–æ—Å: "{user_message}"
"""

            styling_messages = [
                {"role": "system", "content": syntra_system_prompt},
                {"role": "user", "content": styling_prompt},
            ]

            logger.info(f"üé® Styling prompt length: {len(styling_prompt)} chars")
            logger.debug(f"üé® STYLING PROMPT:\n{styling_prompt}\n{'='*80}")

            # Stream styled response with GPT-4o (best model for creativity)
            stream = await self.openai_client.chat.completions.create(
                model=ModelConfig.GPT_4O,  # ‚ö° Always use 4o for styling
                messages=styling_messages,
                max_tokens=ModelConfig.MAX_TOKENS_RESPONSE,
                temperature=ModelConfig.DEFAULT_TEMPERATURE,  # 0.85 for creativity
                stream=True,
            )

            step2_input_tokens = 0
            step2_output_tokens = 0
            full_response = ""

            # Stream response to user
            async for chunk in stream:
                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    yield content

                # Track tokens
                if hasattr(chunk, "usage") and chunk.usage:
                    step2_input_tokens = chunk.usage.prompt_tokens
                    step2_output_tokens = chunk.usage.completion_tokens

            # Estimate tokens if not provided
            if step1_input_tokens == 0:
                step1_input_tokens = self.count_tokens(self.ANALYSIS_SYSTEM_PROMPT + user_message)
            if step1_output_tokens == 0:
                step1_output_tokens = self.count_tokens(structured_analysis)
            if step2_input_tokens == 0:
                step2_input_tokens = self.count_tokens(syntra_system_prompt + styling_prompt)
            if step2_output_tokens == 0:
                step2_output_tokens = self.count_tokens(full_response)

            # Calculate total cost
            step1_cost = self.calculate_cost(
                ModelConfig.GPT_4O_MINI, step1_input_tokens, step1_output_tokens
            )
            step2_cost = self.calculate_cost(
                ModelConfig.GPT_4O, step2_input_tokens, step2_output_tokens
            )
            total_cost = step1_cost + step2_cost

            # Save assistant response to history (only for tiers with save_chat_history=True)
            if should_save_chat_history(tier_enum):
                await add_chat_message(
                    session, user_id=user_id, role="assistant", content=full_response
                )
                logger.debug(f"Assistant response saved to history for tier {user_tier}")
            else:
                logger.debug(
                    f"Assistant response NOT saved to history for tier {user_tier} (save_chat_history=False)"
                )

            # Track cost
            await track_cost(
                session,
                user_id=user_id,
                service="openai_two_step",
                model="mini+4o",
                tokens=(
                    step1_input_tokens
                    + step2_input_tokens
                    + step1_output_tokens
                    + step2_output_tokens
                ),
                cost=total_cost,
            )

            logger.info(
                f"‚úÖ Two-step complete for user {user_id}\n"
                f"   Step 1 (mini): {step1_input_tokens}+"
                f"{step1_output_tokens} tokens, ${step1_cost:.4f}\n"
                f"   Step 2 (4o):   {step2_input_tokens}+"
                f"{step2_output_tokens} tokens, ${step2_cost:.4f}\n"
                f"   Total: ${total_cost:.4f}, Tools: {len(tool_calls_made)}"
            )

        except Exception as e:
            logger.exception(f"‚ùå Error in two-step completion: {e}")
            yield ""


# Global instance
two_step_service = TwoStepOpenAIService()
